"""
milan2026_pipeline.py
=====================
Winter Olympics-focused pipeline for Milan 2026.

Flows (in execution order):
  1. Narratives    â€” ceremony / cultural pages.  Always runs in PRE + LIVE.
  2. Rumors        â€” unconfirmed reports (performer lineups, schedule changes).
                     PRE + LIVE.  Each rumor carries a confidence level and a
                     source.  A rumor can be promoted to a narrative if it gets
                     confirmed on a subsequent run.
  3. Injuries      â€” injury / fitness status for key athletes.  PRE + LIVE.
                     Each injury record has a severity (low / moderate / high)
                     and affects the athlete's vector on the next athlete pass.
  4. Events        â€” Winter event results.  LIVE only.
  5. Athletes      â€” enriched profiles.  Always runs.  Cross-references
                     EVENT_RESULTS, INJURIES, and RUMORS to build a single
                     rich vector per athlete.
  6. Upset detect         â€” LIVE only, after events.  Any individual
                           medalist not on the favorites roster gets a
                           dedicated upset vector.  Skips team events.
  7. Country upset detect â€” LIVE only, after events.  Three signals:
                           â€¢ team_event: favored country lost gold in a
                             team event (hockey, curling).
                           â€¢ surge: a country's gold count exceeds its
                             historical baseline by more than the threshold.
                           â€¢ shutout: an expected country is entirely absent
                             from a podium.

Freshness SLAs (target max staleness during LIVE):
  narrative       60 min
  rumor           20 min   â† rumors confirm or die fast
  injury          15 min   â† can flip same-day
  athlete         30 min
  event           15 min
  upset            5 min
  country_upset    5 min   â† same urgency as individual upsets

Tracks every vector touched this run and prints a GitHub-Actions-friendly
summary at the end.
"""

from datetime import datetime, timezone
import logging
import time
import re

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LOGGING
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Format: timestamp (UTC, seconds), level, message.
# GitHub Actions captures stdout at all levels; local dev can set
# PIPELINE_LOG_LEVEL=DEBUG to see fetch noise.
import os as _os
logging.basicConfig(
    level=getattr(logging, _os.getenv("PIPELINE_LOG_LEVEL", "INFO").upper(), logging.INFO),
    format="%(asctime)s  %(levelname)-8s %(message)s",
    datefmt="%Y-%m-%dT%H:%M:%SZ",
    force=True,          # override any root config already set
)
log = logging.getLogger("milan2026_pipeline")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONFIG
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GAMES_START = datetime(2026, 2, 5, tzinfo=timezone.utc)   # women's hockey prelims start Feb 5, day before Opening Ceremony
GAMES_END   = datetime(2026, 2, 22, 23, 59, tzinfo=timezone.utc)

FRESHNESS_SLA_MINUTES = {
    "narrative":      60,
    "rumor":          20,   # rumors confirm or die fast â€” poll often
    "injury":         15,   # injury status can flip same-day; same cadence as events
    "athlete":        30,
    "event":          15,
    "upset":           5,
    "country_upset":   5,   # same urgency as individual upsets
}

# Known favorites / defending champions.
# Upset detection checks gold medalists against this list.
# IMPORTANT: slugs here must match what slug() produces.  Characters like
# Ã¸ and Ã¡ get stripped by the regex, so "BjÃ¸rgen" â†’ "bj_rgen" and
# "LedeckÃ¡" â†’ "ledeck".  Verify with: print(slug("Name"))
KNOWN_FAVORITES = {
    "yuzuru_hanyu",
    "ester_ledeck",           # Ester LedeckÃ¡ â€” Ã¡ stripped
    "jessie_diggins",
    "john_shuster",
    "kendall_coyne_schofield",
    "danny_o_shea",
    "lee_stecklein",
    "mikaela_shiffrin",
    "irene_schouten",         # defending Olympic champion
    "therese_johaug",
}

# â”€â”€ Team events â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Individual upset detection skips these (team names like "USA Women"
# can't match an individual-athlete slug).  Country-level detection
# handles them instead, using TEAM_EVENT_FAVORITES below.
TEAM_EVENTS = {
    "Women's ice hockey tournament",
    "Men's curling",
}

# â”€â”€ Country-level upset config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TEAM_EVENT_FAVORITES: which country is expected to win gold in each
# team event.  If someone else wins gold â†’ country_upset vector.
TEAM_EVENT_FAVORITES = {
    "Women's ice hockey tournament": "USA",   # USA women historically dominant
    "Men's curling":                 "USA",   # Shuster's team defending 2018 gold
}

# HISTORICAL_GOLD_BASELINE: how many golds each country is realistically
# expected to win across the full set of events we're tracking.  Used by
# surge detection.  Countries not listed default to 0.
HISTORICAL_GOLD_BASELINE = {
    "USA": 1,
    "NOR": 1,   # cross-country powerhouse
    "JPN": 1,   # figure skating
    "SWE": 0,
    "NED": 0,   # speed skating specialist
    "CAN": 0,
    "CZE": 0,
    "FIN": 0,
}

# COUNTRY_SURGE_THRESHOLD: a country must exceed its gold baseline by
# MORE than this number to trigger a surge vector.  At 1, a country
# that picks up exactly one extra gold is "nice run" not "surge".
# Two extra golds is a genuine surprise worth surfacing.
COUNTRY_SURGE_THRESHOLD = 1

# EVENT_EXPECTED_COUNTRIES: for shutout detection.  Which countries are
# expected to appear somewhere on the podium for each event.  If an
# expected country is entirely absent â†’ shutout vector.
EVENT_EXPECTED_COUNTRIES = {
    "Women's downhill alpine skiing":      {"USA", "CZE"},
    "Men's figure skating free skate":     {"JPN"},            # JPN sweep in stubs
    "Women's ice hockey tournament":       {"USA", "CAN"},
    "Women's cross-country skiathlon":     {"NOR", "USA"},
    "Men's curling":                       {"USA"},
    "Women's 500m speed skating":          {"USA", "NED"},
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PINECONE + EMBEDDING MODEL
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Only initialised when PINECONE_API_KEY is present (CI / production).
# When it's absent (tests, local dev) everything falls back to the
# in-memory VECTOR_STORE below â€” no embedding, no network call.
INDEX_NAME   = "milan-2026-olympics"
MODEL_NAME   = "all-MiniLM-L6-v2"   # must match the app's query model

_pinecone_index = None
_embedder       = None

def _init_pinecone():
    """Connect to Pinecone and load the embedding model.
    Called once at the top of main() when the API key is available."""
    global _pinecone_index, _embedder
    from pinecone import Pinecone
    from sentence_transformers import SentenceTransformer

    log.info("connecting to Pinecone index '%s'â€¦", INDEX_NAME)
    pc = Pinecone(api_key=_os.getenv("PINECONE_API_KEY"))
    _pinecone_index = pc.Index(INDEX_NAME)
    stats = _pinecone_index.describe_index_stats()
    log.info("Pinecone ready â€” %d vectors currently in index", stats["total_vector_count"])

    log.info("loading embedding model '%s'â€¦", MODEL_NAME)
    _embedder = SentenceTransformer(MODEL_NAME)
    log.info("embedding model ready (dim=%d)", _embedder.get_sentence_embedding_dimension())

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# VECTOR STORE (in-memory fallback for tests)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VECTOR_STORE = {}   # vector_id â†’ {text, metadata}

def upsert_vector(vector_id: str, text: str, metadata: dict) -> str:
    """Upsert a vector.

    If Pinecone is initialised (production / CI):
        embed text â†’ upsert to Pinecone â†’ mirror to VECTOR_STORE.
    Otherwise (tests / local dev):
        write to VECTOR_STORE only.
    """
    action = "inserted" if vector_id not in VECTOR_STORE else "updated"

    if _pinecone_index is not None:
        # Real path: embed + upsert
        embedding = _embedder.encode(text).tolist()
        metadata_with_text = {**metadata, "text": text}
        _pinecone_index.upsert(vectors=[{
            "id":       vector_id,
            "values":   embedding,
            "metadata": metadata_with_text,
        }])

    # Always mirror to in-memory store (tests read it for assertions)
    VECTOR_STORE[vector_id] = {"text": text, "metadata": metadata}
    log.info("upsert %-8s â†’ %s", action.upper(), vector_id)
    return action

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UTILS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def resolve_mode(now: datetime | None = None) -> str:
    now = now or datetime.now(timezone.utc)
    if now < GAMES_START:
        return "PRE_GAMES"
    if GAMES_START <= now <= GAMES_END:
        return "LIVE_GAMES"
    return "DORMANT"

def freshness_metadata(source: str, volatility: str) -> dict:
    return {
        "source": source,
        "volatility": volatility,
        "last_fetched_utc": datetime.now(timezone.utc)
        .isoformat(timespec="seconds")
        .replace("+00:00", "Z"),
    }

def slug(s: str) -> str:
    return re.sub(r"[^a-z0-9]+", "_", s.lower()).strip("_")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DISCOVER ENTITIES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def discover_entities(mode: str) -> dict:
    """
    Returns all entity lists the pipeline needs.
    Athletes carry structured metadata; rumors and injuries are
    separate signal lists that feed into the athlete enrichment step.
    """
    entities = {
        "narratives": [
            "Opening ceremony",
            "Closing ceremony",
            "Cultural program",
        ],

        # â”€â”€ rumors: unconfirmed reports that matter for the chatbot.
        #   confidence: 0.0â€“1.0.  â‰¥0.8 means "almost confirmed".
        #   related_entity: ties the rumor to a narrative or athlete vector
        #     so the chatbot can link them when answering questions.
        #   status: "unconfirmed" | "confirmed" | "denied".
        #     confirmed rumors get promoted to narratives on the next run;
        #     denied rumors get their vectors deleted.
        "rumors": [
            {
                "id":              "bocelli_opening",
                "headline":        "Andrea Bocelli rumored to perform at Milano Cortina Opening Ceremony",
                "detail":          "Multiple Italian media outlets report that tenor Andrea Bocelli is in advanced discussions to headline the Opening Ceremony musical segment. No official confirmation from the Milano Cortina organizing committee yet.",
                "confidence":      0.75,
                "source":          "Italian sports press",
                "related_entity":  "Opening ceremony",
                "status":          "unconfirmed",
            },
        ],

        # â”€â”€ injuries: fitness / injury status for athletes whose
        #   participation or performance could be affected.
        #   severity: low (minor, train through it) |
        #             moderate (may miss events or perform below peak) |
        #             high (likely withdrawal).
        #   event_impact: which of their scheduled events are at risk.
        "injuries": [
            {
                "athlete":        "Mikaela Shiffrin",
                "condition":      "Left ankle sprain â€” sustained during a World Cup giant slalom in Val d'IsÃ¨re. Cleared for travel but training load reduced heading into the Games.",
                "severity":       "moderate",
                "status":         "training with modifications",
                "event_impact":   ["Women's downhill alpine skiing"],
                "source":         "USSA official statement",
            },
        ],

        # â”€â”€ athletes â”€â”€
        "athletes": [
            {"name": "Mikaela Shiffrin",           "events": ["Women's downhill alpine skiing"],                          "favorite": True},
            {"name": "Yuzuru Hanyu",               "events": ["Men's figure skating free skate"],                         "favorite": True},
            {"name": "Ester LedeckÃ¡",              "events": ["Women's downhill alpine skiing", "Women's sprint"],        "favorite": True},
            {"name": "Jessie Diggins",             "events": ["Women's cross-country skiathlon"],                         "favorite": True},
            {"name": "John Shuster",               "events": ["Men's curling"],                                           "favorite": True},
            {"name": "Kendall Coyne Schofield",    "events": ["Women's 500m speed skating"],                              "favorite": True},
            {"name": "Danny O'Shea",               "events": ["Men's pairs figure skating"],                              "favorite": True},
            {"name": "Lee Stecklein",              "events": ["Women's ice hockey"],                                      "favorite": True},
            {"name": "Irene Schouten",             "events": ["Women's 500m speed skating"],                              "favorite": True},
            {"name": "Therese Johaug",             "events": ["Women's cross-country skiathlon"],                         "favorite": True},
        ],

        "events": [],
    }
    if mode == "LIVE_GAMES":
        entities["events"] = [
            "Women's downhill alpine skiing",
            "Men's figure skating free skate",
            "Women's ice hockey tournament",
            "Women's cross-country skiathlon",
            "Men's curling",
            "Women's 500m speed skating",
        ]
    return entities

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FETCH STUBS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_page(title: str) -> str:
    log.debug("fetch narrative: %s", title)
    return f"Latest updated content for {title}."

def fetch_athlete_bio(name: str) -> str:
    log.debug("fetch athlete bio: %s", name)
    bios = {
        "Lindsey Vonn":            "Three-time Olympic medalist in alpine skiing. Known for aggressive downhill technique and fierce rivalries.",
        "Nathan Chen":             "2022 Olympic gold medalist in men's figure skating. Holds the world record for most quadruple jumps in a single program.",
        "Marit BjÃ¸rgen":           "Most decorated female Winter Olympian in history. Dominant cross-country skier across four Olympics.",
        "Yuzuru Hanyu":            "Back-to-back Olympic gold medalist (2014, 2018). Pioneered the first competitive quad Axel attempt.",
        "Ester LedeckÃ¡":           "Czech athlete competing in both alpine skiing and sprint cycling â€” one of the most versatile Winter Olympians ever.",
        "Jessie Diggins":          "2022 Olympic gold medalist in cross-country skiing. First American woman to win Olympic cross-country gold.",
        "John Shuster":            "Led the USA to curling gold at 2018 PyeongChang. Veteran skip with three Olympic appearances.",
        "Kendall Coyne Schofield": "2018 Olympic gold medalist in speed skating. Known for blazing 500m times.",
        "Danny O'Shea":            "Rising star in pairs figure skating. Making his Olympic debut at Milano Cortina 2026.",
        "Lee Stecklein":           "USA women's ice hockey captain. Two-time Olympic gold medalist (2018, 2022).",
    }
    return bios.get(name, f"Athlete profile for {name}.")

def fetch_rumor(rumor: dict) -> dict:
    """
    In production this would re-scrape the source to check for updates.
    Stub returns the rumor as-is (simulates a fresh fetch with no status change).
    """
    log.debug("fetch rumor: %s", rumor["id"])
    return rumor

def fetch_injury(injury: dict) -> dict:
    """
    In production this would re-scrape team/league injury reports.
    Stub returns the injury as-is.
    """
    log.debug("fetch injury: %s", injury["athlete"])
    return injury

def fetch_event_results(event_name: str) -> list[dict]:
    log.debug("fetch event results: %s", event_name)
    STUBBED_RESULTS = {
        "Women's downhill alpine skiing": [
            {"rank": 1, "name": "Sara Hector",       "country": "SWE"},   # NOT a favorite â†’ upset
            {"rank": 2, "name": "Mikaela Shiffrin",   "country": "USA"},   # favorite, silver
            {"rank": 3, "name": "Ester LedeckÃ¡",      "country": "CZE"},
        ],
        "Men's figure skating free skate": [
            {"rank": 1, "name": "Yuzuru Hanyu",      "country": "JPN"},   # favorite wins
            {"rank": 2, "name": "Kagiyama Kaito",    "country": "JPN"},
            {"rank": 3, "name": "Shoma Uno",         "country": "JPN"},   # NOT a favorite â†’ upset
        ],
        "Women's ice hockey tournament": [
            {"rank": 1, "name": "Canada Women",      "country": "CAN"},   # NOT in favorites â†’ upset
            {"rank": 2, "name": "USA Women",         "country": "USA"},
            {"rank": 3, "name": "Finland Women",     "country": "FIN"},
        ],
        "Women's cross-country skiathlon": [
            {"rank": 1, "name": "Jessie Diggins",    "country": "USA"},   # favorite wins
            {"rank": 2, "name": "Maja Dahlmeier",    "country": "GER"},
            {"rank": 3, "name": "Therese Johaug",    "country": "NOR"},   # favorite, bronze
        ],
        "Men's curling": [
            {"rank": 1, "name": "Sweden Men",        "country": "SWE"},   # NOT a favorite â†’ upset
            {"rank": 2, "name": "USA Men",           "country": "USA"},
            {"rank": 3, "name": "Norway Men",        "country": "NOR"},
        ],
        "Women's 500m speed skating": [
            {"rank": 1, "name": "Irene Schouten",    "country": "NED"},   # favorite wins (defending champ)
            {"rank": 2, "name": "Kendall Coyne Schofield", "country": "USA"},
            {"rank": 3, "name": "Nao Kodaira",       "country": "JPN"},   # NOT a favorite â†’ upset
        ],
    }
    return STUBBED_RESULTS.get(event_name, [
        {"rank": 1, "name": f"{event_name} Gold",   "country": "USA"},
        {"rank": 2, "name": f"{event_name} Silver", "country": "CAN"},
        {"rank": 3, "name": f"{event_name} Bronze", "country": "NOR"},
    ])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TRACKING â€” shared state built up across pipeline passes
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
UPDATED_VECTORS      = []   # (vector_id, action)
EVENT_RESULTS_THIS_RUN = {} # event_name â†’ [medalists]
INJURIES_THIS_RUN     = {}  # athlete_slug â†’ injury dict
RUMORS_THIS_RUN       = []  # list of fetched rumor dicts

def upsert_document(vector_id: str, text: str, metadata: dict):
    action = upsert_vector(vector_id, text, metadata)
    UPDATED_VECTORS.append((vector_id, action))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UPSERT HELPERS â€” narratives
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def upsert_narrative(title: str, text: str):
    vid = f"page::{slug(title)}"
    upsert_document(vid, text, {
        "doc_type": "narrative",
        "title":    title,
        **freshness_metadata("wikipedia", "high"),
    })

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UPSERT HELPERS â€” rumors
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def upsert_rumor(rumor: dict):
    """
    Writes a rumor vector.  The vector text is written so the LLM
    naturally hedges ("rumored", "unconfirmed") when it surfaces this.

    Lifecycle:
      unconfirmed â†’ vector exists, confidence in metadata
      confirmed   â†’ promoted: upsert into the related narrative instead,
                    then delete the rumor vector
      denied      â†’ delete the rumor vector, no replacement
    """
    rid    = rumor["id"]
    status = rumor["status"]
    vid    = f"rumor::{rid}"

    if status == "confirmed":
        # Promote: merge into the related narrative
        log.warning("rumor CONFIRMED â†’ promoting to narrative: %s", rid)
        related = rumor.get("related_entity", rid)
        promoted_text = (
            f"CONFIRMED: {rumor['headline']}\n"
            f"{rumor['detail']}\n"
            f"(Originally reported as unconfirmed; now confirmed by {rumor['source']}.)"
        )
        upsert_narrative(related, promoted_text)
        # Rumor vector no longer needed â€” mark for deletion in real Pinecone.
        # In this sim we just skip writing it.
        log.warning("rumor vector %s deleted (confirmed â†’ narrative)", vid)
        return

    if status == "denied":
        log.warning("rumor DENIED â†’ vector %s deleted", vid)
        return

    # status == "unconfirmed" â€” write the rumor vector
    confidence = rumor.get("confidence", 0.5)
    conf_label = "low" if confidence < 0.4 else "moderate" if confidence < 0.7 else "high"

    text = (
        f"RUMOR ({conf_label} confidence) â€” {rumor['headline']}\n"
        f"{rumor['detail']}\n"
        f"Source: {rumor['source']}.\n"
        f"Status: Unconfirmed as of this update. Treat as unverified."
    )
    upsert_document(vid, text, {
        "doc_type":       "rumor",
        "rumor_id":       rid,
        "confidence":     confidence,
        "conf_label":     conf_label,
        "status":         status,
        "related_entity": rumor.get("related_entity"),
        **freshness_metadata(rumor.get("source", "press"), "very_high"),
    })

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UPSERT HELPERS â€” injuries
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def upsert_injury(injury: dict):
    """
    Writes an injury vector AND caches it in INJURIES_THIS_RUN so
    the athlete enrichment pass can stamp injury_risk onto the athlete vector.
    """
    athlete  = injury["athlete"]
    severity = injury["severity"]
    vid      = f"injury::{slug(athlete)}"

    # Cache for athlete enrichment
    INJURIES_THIS_RUN[slug(athlete)] = injury

    severity_icon = {"low": "ðŸŸ¡", "moderate": "ðŸŸ ", "high": "ðŸ”´"}.get(severity, "âšª")

    text = (
        f"INJURY REPORT â€” {athlete}\n"
        f"Severity: {severity.upper()} {severity_icon}\n"
        f"Condition: {injury['condition']}\n"
        f"Status: {injury['status']}\n"
        f"Events at risk: {', '.join(injury.get('event_impact', []) or ['None identified'])}.\n"
        f"Source: {injury.get('source', 'unattributed')}."
    )
    upsert_document(vid, text, {
        "doc_type":     "injury",
        "athlete":      athlete,
        "severity":     severity,
        "status":       injury.get("status"),
        "event_impact": injury.get("event_impact", []),
        **freshness_metadata(injury.get("source", "team_report"), "very_high"),
    })

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UPSERT HELPERS â€” events
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def upsert_event(event_name: str, medalists: list[dict]):
    vid = f"event::{slug(event_name)}"
    lines = [f"{m['rank']}. {m['name']} ({m['country']})" for m in medalists]
    text  = f"Event results â€” {event_name}\n" + "\n".join(lines)
    upsert_document(vid, text, {
        "doc_type":  "event_result",
        "event":     event_name,
        "medalists": medalists,
        **freshness_metadata("wikipedia", "low"),
    })
    EVENT_RESULTS_THIS_RUN[event_name] = medalists

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UPSERT HELPERS â€” athletes (enriched)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def upsert_athlete(athlete: dict):
    """
    Builds one rich vector per athlete by layering:
      1. Bio (fetched)
      2. Medal status (from EVENT_RESULTS_THIS_RUN)
      3. Injury status (from INJURIES_THIS_RUN â€” if present, adds a warning)
      4. Scheduled events + favorite flag
    """
    name      = athlete["name"]
    vid       = f"athlete::{slug(name)}"
    bio       = fetch_athlete_bio(name)
    favorite  = athlete.get("favorite", False)
    scheduled = athlete.get("events", [])

    # â”€â”€ medal status â”€â”€
    medal_lines = []
    for event_name, medalists in EVENT_RESULTS_THIS_RUN.items():
        for m in medalists:
            if slug(m["name"]) == slug(name):
                ordinal = {1: "Gold", 2: "Silver", 3: "Bronze"}
                medal_lines.append(f"  {ordinal.get(m['rank'], '?')} â€” {event_name}")

    # â”€â”€ injury status â”€â”€
    injury_info = INJURIES_THIS_RUN.get(slug(name))

    # â”€â”€ assemble â”€â”€
    sections = [
        f"Athlete: {name}",
        f"Bio: {bio}",
        f"Favorite: {'Yes' if favorite else 'No'}",
        f"Scheduled events: {', '.join(scheduled) if scheduled else 'None'}",
    ]

    if medal_lines:
        sections.append("Medals this Games:\n" + "\n".join(medal_lines))
    else:
        sections.append("Medals this Games: None yet.")

    if injury_info:
        sev_icon = {"low": "ðŸŸ¡", "moderate": "ðŸŸ ", "high": "ðŸ”´"}.get(injury_info["severity"], "âšª")
        sections.append(
            f"âš ï¸  INJURY FLAG {sev_icon} â€” {injury_info['severity'].upper()}\n"
            f"  Condition: {injury_info['condition']}\n"
            f"  Status: {injury_info['status']}\n"
            f"  Events at risk: {', '.join(injury_info.get('event_impact', []))}"
        )

    text = "\n".join(sections)

    upsert_document(vid, text, {
        "doc_type":         "athlete",
        "name":             name,
        "favorite":         favorite,
        "scheduled_events": scheduled,
        "has_medal":        len(medal_lines) > 0,
        "injury_risk":      injury_info["severity"] if injury_info else None,
        **freshness_metadata("wikipedia", "very_high"),
    })

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UPSERT HELPERS â€” upsets
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def upsert_upset(event_name: str, medalist: dict):
    name    = medalist["name"]
    country = medalist["country"]
    rank    = medalist["rank"]
    ordinal = {1: "Gold", 2: "Silver", 3: "Bronze"}.get(rank, "Medal")

    vid  = f"upset::{slug(event_name)}_{slug(name)}"
    text = (
        f"UPSET â€” {event_name}\n"
        f"{name} ({country}) won {ordinal} â€” an unexpected result.\n"
        f"{name} was not among the pre-Games favorites for this event.\n"
        f"This is one of the surprise storylines of Milano Cortina 2026."
    )
    upsert_document(vid, text, {
        "doc_type": "upset",
        "event":    event_name,
        "athlete":  name,
        "country":  country,
        "medal":    ordinal,
        **freshness_metadata("results_scraper", "very_high"),
    })
    log.info("UPSET: %s (%s) â€” %s in %s", name, country, ordinal, event_name)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UPSET DETECTION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def detect_upsets():
    """
    Skips TEAM_EVENTS â€” collective names like "USA Women" can't be
    checked against an individual-athlete favorites roster.
    For individual events: any medalist not in KNOWN_FAVORITES gets
    a dedicated upset vector.
    """
    log.info("â”€â”€ upset detection (individual) â”€â”€")
    upsets_found = 0
    for event_name, medalists in EVENT_RESULTS_THIS_RUN.items():
        if event_name in TEAM_EVENTS:
            log.debug("skipping team event: %s", event_name)
            continue
        for m in medalists:
            if slug(m["name"]) not in KNOWN_FAVORITES:
                upsert_upset(event_name, m)
                upsets_found += 1
    if upsets_found == 0:
        log.debug("no individual upsets this run")
    return upsets_found

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# COUNTRY-LEVEL UPSET DETECTION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def upsert_country_upset(country: str, signal_type: str, detail: str, metadata_extra: dict):
    """
    Writes a country_upset:: vector.  signal_type is one of:
      team_event  â€” a favored country lost gold in a team event
      surge       â€” a country exceeded its historical gold baseline
      shutout     â€” a favored country failed to medal in an expected event
    """
    vid  = f"country_upset::{signal_type}_{slug(country)}"
    # If there's already a vector for this country+signal (e.g. multiple
    # shutouts for the same country), append a unique event tag.
    if "event" in metadata_extra:
        vid = f"country_upset::{signal_type}_{slug(country)}_{slug(metadata_extra['event'])}"

    text = (
        f"COUNTRY UPSET ({signal_type.replace('_', ' ').upper()}) â€” {country}\n"
        f"{detail}\n"
        f"This is a notable storyline at Milano Cortina 2026."
    )
    upsert_document(vid, text, {
        "doc_type":    "country_upset",
        "country":     country,
        "signal_type": signal_type,
        **metadata_extra,
        **freshness_metadata("results_scraper", "very_high"),
    })
    log.info("COUNTRY UPSET (%s): %s", signal_type, country)


def detect_country_upsets():
    """
    Three independent signals, all built from EVENT_RESULTS_THIS_RUN:

    1. TEAM EVENT â€” for each event in TEAM_EVENT_FAVORITES, check whether
       the favored country actually won gold.  If not, the country that
       DID win gold gets a country_upset vector.

    2. SURGE â€” tally all golds across every event this run.  Any country
       whose gold count exceeds HISTORICAL_GOLD_BASELINE by more than
       COUNTRY_SURGE_THRESHOLD gets a surge vector.

    3. SHUTOUT â€” for each event in EVENT_EXPECTED_COUNTRIES, check whether
       every expected country appears at least once on the podium.  If an
       expected country is entirely absent, it gets a shutout vector.
    """
    log.info("â”€â”€ upset detection (country) â”€â”€")
    country_upsets_found = 0

    # â”€â”€ build medal tally (golds only for surge; full for shutout) â”€â”€
    gold_tally = {}   # country â†’ int
    for event_name, medalists in EVENT_RESULTS_THIS_RUN.items():
        for m in medalists:
            c = m["country"]
            if m["rank"] == 1:
                gold_tally[c] = gold_tally.get(c, 0) + 1

    # â”€â”€ Signal 1: team event upsets â”€â”€
    log.debug("[1/3] team event check")
    for event_name, favored_country in TEAM_EVENT_FAVORITES.items():
        if event_name not in EVENT_RESULTS_THIS_RUN:
            continue
        gold_winner = next(
            (m for m in EVENT_RESULTS_THIS_RUN[event_name] if m["rank"] == 1),
            None
        )
        if gold_winner and gold_winner["country"] != favored_country:
            actual_country = gold_winner["country"]
            upsert_country_upset(
                country=actual_country,
                signal_type="team_event",
                detail=(
                    f"{actual_country} won gold in {event_name}, "
                    f"defeating {favored_country} who were the pre-Games favorites. "
                    f"Winner: {gold_winner['name']}."
                ),
                metadata_extra={
                    "event":            event_name,
                    "favored_country":  favored_country,
                    "winner_name":      gold_winner["name"],
                },
            )
            country_upsets_found += 1
        else:
            log.debug("%s: %s won as expected", event_name, favored_country)

    # â”€â”€ Signal 2: country surge â”€â”€
    log.debug("[2/3] surge check")
    for country, golds in sorted(gold_tally.items(), key=lambda x: -x[1]):
        baseline = HISTORICAL_GOLD_BASELINE.get(country, 0)
        delta    = golds - baseline
        if delta > COUNTRY_SURGE_THRESHOLD:
            upsert_country_upset(
                country=country,
                signal_type="surge",
                detail=(
                    f"{country} has won {golds} gold medal{'s' if golds != 1 else ''} "
                    f"â€” {delta} more than the {baseline} expected based on historical performance. "
                    f"A genuine surprise run at these Games."
                ),
                metadata_extra={
                    "golds_actual":   golds,
                    "golds_baseline": baseline,
                    "delta":          delta,
                },
            )
            country_upsets_found += 1
        else:
            log.debug("%s: %d golds (baseline %d, Î”%+d) â€” within threshold", country, golds, baseline, delta)

    # â”€â”€ Signal 3: shutouts â”€â”€
    log.debug("[3/3] shutout check")
    for event_name, expected_countries in EVENT_EXPECTED_COUNTRIES.items():
        if event_name not in EVENT_RESULTS_THIS_RUN:
            continue
        actual_countries = {m["country"] for m in EVENT_RESULTS_THIS_RUN[event_name]}
        for ec in expected_countries:
            if ec not in actual_countries:
                upsert_country_upset(
                    country=ec,
                    signal_type="shutout",
                    detail=(
                        f"{ec} was expected to medal in {event_name} "
                        f"but did not appear on the podium â€” a significant absence."
                    ),
                    metadata_extra={"event": event_name},
                )
                country_upsets_found += 1
            else:
                log.debug("%s medaled in %s", ec, event_name)

    if country_upsets_found == 0:
        log.debug("no country-level upsets this run")
    return country_upsets_found

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SUMMARY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def summarize_updates(updated_list: list[tuple[str, str]]) -> dict:
    summary = {
        "narratives":     [],
        "rumors":         [],
        "injuries":       [],
        "athletes":       [],
        "events":         [],
        "upsets":         [],
        "country_upsets": [],
    }
    for vid, action in updated_list:
        record = f"{vid} ({action})"
        # country_upset:: checked before upset:: â€” longer prefix, same start
        if   vid.startswith("athlete::"):        summary["athletes"].append(record)
        elif vid.startswith("event::"):          summary["events"].append(record)
        elif vid.startswith("country_upset::"):  summary["country_upsets"].append(record)
        elif vid.startswith("upset::"):          summary["upsets"].append(record)
        elif vid.startswith("rumor::"):          summary["rumors"].append(record)
        elif vid.startswith("injury::"):         summary["injuries"].append(record)
        else:                                    summary["narratives"].append(record)
    return summary

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MAIN PIPELINE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    mode = resolve_mode()
    log.info("=" * 60)
    log.info("PIPELINE MODE: %s", mode)
    log.info("run started: %s", datetime.now(timezone.utc).isoformat(timespec="seconds"))
    log.info("=" * 60)

    if mode == "DORMANT":
        log.info("DORMANT â€” exiting without updates")
        return

    # Connect to Pinecone when the key is available (CI / production).
    # Absent key â†’ in-memory VECTOR_STORE only (tests / local dev).
    if _os.getenv("PINECONE_API_KEY"):
        _init_pinecone()
    else:
        log.info("PINECONE_API_KEY not set â€” using in-memory store only")

    entities = discover_entities(mode)

    # â”€â”€ 1. Narratives â”€â”€
    log.info("â”€â”€ narratives â”€â”€")
    for page in entities["narratives"]:
        text = fetch_page(page)
        upsert_narrative(page, text)
        time.sleep(0.1)

    # â”€â”€ 2. Rumors â”€â”€
    #    Runs before athletes so that if a rumor is about an athlete
    #    (future expansion), the athlete pass could reference it.
    log.info("â”€â”€ rumors â”€â”€")
    for rumor in entities["rumors"]:
        fresh = fetch_rumor(rumor)
        RUMORS_THIS_RUN.append(fresh)
        upsert_rumor(fresh)
        time.sleep(0.1)

    # â”€â”€ 3. Injuries â”€â”€
    #    Must run before athletes â€” populates INJURIES_THIS_RUN
    #    which the athlete enrichment step reads.
    log.info("â”€â”€ injuries â”€â”€")
    for injury in entities["injuries"]:
        fresh = fetch_injury(injury)
        upsert_injury(fresh)
        time.sleep(0.1)

    # â”€â”€ 4. Events (LIVE only) â”€â”€
    #    Must run before athletes â€” populates EVENT_RESULTS_THIS_RUN.
    if mode == "LIVE_GAMES":
        log.info("â”€â”€ events â”€â”€")
        for event_name in entities["events"]:
            medalists = fetch_event_results(event_name)
            upsert_event(event_name, medalists)
            time.sleep(0.1)

    # â”€â”€ 5. Athletes (enriched: bio + medals + injuries) â”€â”€
    log.info("â”€â”€ athletes â”€â”€")
    for athlete in entities["athletes"]:
        upsert_athlete(athlete)
        time.sleep(0.1)

    # â”€â”€ 6. Upset detection â€” individual (LIVE only) â”€â”€
    if mode == "LIVE_GAMES":
        log.info("â”€â”€ upset detection (individual) â”€â”€")
        detect_upsets()

    # â”€â”€ 7. Upset detection â€” country (LIVE only) â”€â”€
    #    Three signals: team_event, surge, shutout.
    #    All built from EVENT_RESULTS_THIS_RUN after events are cached.
    if mode == "LIVE_GAMES":
        log.info("â”€â”€ upset detection (country) â”€â”€")
        detect_country_upsets()

    # â”€â”€ Summary â”€â”€
    summary = summarize_updates(UPDATED_VECTORS)
    log.info("=" * 60)
    log.info("UPDATE SUMMARY")
    log.info("=" * 60)
    for key, items in summary.items():
        flag = "ðŸš¨" if key in ("upsets", "country_upsets") and items else "  "
        log.info("%s %s (%d):", flag, key.upper(), len(items))
        for item in items:
            log.info("   - %s", item)

    log.info("total vectors touched: %d", len(UPDATED_VECTORS))
    log.info("pipeline run complete")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    main()
